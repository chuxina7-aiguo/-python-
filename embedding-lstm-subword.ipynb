{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport sklearn\nimport pandas as pd\nimport os\nimport sys\nimport time\nimport tensorflow as tf\n\nfrom tensorflow import keras\n\nprint(tf.__version__)\nprint(sys.version_info)\nfor module in mpl, np, pd, sklearn, tf,:\n    print(module.__name__, module.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-02T07:56:58.509526Z","iopub.execute_input":"2024-02-02T07:56:58.509953Z","iopub.status.idle":"2024-02-02T07:56:58.524641Z","shell.execute_reply.started":"2024-02-02T07:56:58.509922Z","shell.execute_reply":"2024-02-02T07:56:58.523254Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"2.15.0\nsys.version_info(major=3, minor=10, micro=13, releaselevel='final', serial=0)\nmatplotlib 3.7.4\nnumpy 1.26.3\npandas 2.2.0\nsklearn 1.2.2\ntensorflow 2.15.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow_datasets as tfds\n\ndataset,info = tfds.load('imdb_reviews/subwords8k',with_info = True,\n                        as_supervised = True\n                        )\ntrain_dataset,test_dataset = dataset['train'],dataset['test']","metadata":{"execution":{"iopub.status.busy":"2024-02-02T08:01:43.972313Z","iopub.execute_input":"2024-02-02T08:01:43.972778Z","iopub.status.idle":"2024-02-02T08:05:52.222908Z","shell.execute_reply.started":"2024-02-02T08:01:43.972748Z","shell.execute_reply":"2024-02-02T08:05:52.221293Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\u001b[1mDownloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Dl Completed...: 0 url [00:00, ? url/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df822a7335814bf49459ebb861a3e332"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Dl Size...: 0 MiB [00:00, ? MiB/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fabc8ca0e9e74327bd26dfc4420a6dfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Shuffling /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incompleteH0GYP2/imdb_reviews-train.tfrecord…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Shuffling /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incompleteH0GYP2/imdb_reviews-test.tfrecord*…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised examples...:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Shuffling /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incompleteH0GYP2/imdb_reviews-unsupervised.t…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\u001b[1mDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"#通过encoder把我们的词语转换为subword形式\n\ntokenizer = info.features['text'].encoder\n\nprint('vocabulary size: {}'.format(tokenizer.vocab_size))","metadata":{"execution":{"iopub.status.busy":"2024-02-02T08:05:58.074406Z","iopub.execute_input":"2024-02-02T08:05:58.075301Z","iopub.status.idle":"2024-02-02T08:05:58.081700Z","shell.execute_reply.started":"2024-02-02T08:05:58.075262Z","shell.execute_reply":"2024-02-02T08:05:58.080382Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"vocabulary size: 8185\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in train_dataset.take(1):\n    print(np.array(i[0]))\n    print(tokenizer.decode(np.array(i[0])))","metadata":{"execution":{"iopub.status.busy":"2024-02-02T08:06:28.859369Z","iopub.execute_input":"2024-02-02T08:06:28.860209Z","iopub.status.idle":"2024-02-02T08:06:29.010506Z","shell.execute_reply.started":"2024-02-02T08:06:28.860146Z","shell.execute_reply":"2024-02-02T08:06:29.008925Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"[  62   18   41  604  927   65    3  644 7968   21   35 5096   36   11\n   43 2948 5240  102   50  681 7862 1244    3 3266   29  122  640    2\n   26   14  279  438   35   79  349  384   11 1991    3  492   79  122\n  188  117   33 4047 4531   14   65 7968    8 1819 3947    3   62   27\n    9   41  577 5044 2629 2552 7193 7961 3642    3   19  107 3903  225\n   85  198   72    1 1512  738 2347  102 6245    8   85  308   79 6936\n 7961   23 4981 8044    3 6429 7961 1141 1335 1848 4848   55 3601 4217\n 8050    2    5   59 3831 1484 8040 7974  174 5773   22 5240  102   18\n  247   26    4 3903 1612 3902  291   11    4   27   13   18 4092 4008\n 7961    6  119  213 2774    3   12  258 2306   13   91   29  171   52\n  229    2 1245 5790  995 7968    8   52 2948 5240 8039 7968    8   74\n 1249    3   12  117 2438 1369  192   39 7975]\nThis was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\n","output_type":"stream"}]},{"cell_type":"code","source":"sample_string = 'Tensorflow is cool.'\n\ntokenized_string = tokenizer.encode(sample_string)\n# tokenize通过encoder把我们的词语转换为subword形式\nprint('Tokenized string is {}'.format(tokenized_string))\nprint(type(tokenized_string))\n\noriginal_string = tokenizer.decode(tokenized_string)\nprint('Original string is {}'.format(original_string))\n\nassert original_string == sample_string","metadata":{"execution":{"iopub.status.busy":"2024-02-02T08:10:04.048040Z","iopub.execute_input":"2024-02-02T08:10:04.048726Z","iopub.status.idle":"2024-02-02T08:10:04.058436Z","shell.execute_reply.started":"2024-02-02T08:10:04.048676Z","shell.execute_reply":"2024-02-02T08:10:04.056875Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Tokenized string is [6307, 2327, 2934, 7961, 9, 2724, 7975]\n<class 'list'>\nOriginal string is Tensorflow is cool.\n","output_type":"stream"}]},{"cell_type":"code","source":"for token in tokenized_string:\n    print('{} -->{}'.format(token,tokenizer.decode([token])))","metadata":{"execution":{"iopub.status.busy":"2024-02-02T08:12:38.612357Z","iopub.execute_input":"2024-02-02T08:12:38.612915Z","iopub.status.idle":"2024-02-02T08:12:38.621643Z","shell.execute_reply.started":"2024-02-02T08:12:38.612880Z","shell.execute_reply":"2024-02-02T08:12:38.620242Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"6307 -->Ten\n2327 -->sor\n2934 -->flow\n7961 --> \n9 -->is \n2724 -->cool\n7975 -->.\n","output_type":"stream"}]},{"cell_type":"code","source":"buffer_size = 10000\nbatch_size = 64\npadded_shapes=tf.compat.v1.data.get_output_shapes(train_dataset)\n\npadded_shapes_test=tf.compat.v1.data.get_output_shapes(test_dataset)\n\nprint(padded_shapes)\n\nprint(padded_shapes_test)\n\ntrain_dataset = train_dataset.shuffle(buffer_size)\n # padded_batch是每批数据分别做padding\ntrain_dataset = train_dataset.padded_batch(batch_size,padded_shapes) \n\ntest_dataset = test_dataset.padded_batch(batch_size,padded_shapes_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T08:57:30.630638Z","iopub.execute_input":"2024-02-02T08:57:30.631084Z","iopub.status.idle":"2024-02-02T08:57:30.652674Z","shell.execute_reply.started":"2024-02-02T08:57:30.631053Z","shell.execute_reply":"2024-02-02T08:57:30.651530Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"(TensorShape([None, None]), TensorShape([None]))\n(TensorShape([None, None]), TensorShape([None]))\n","output_type":"stream"}]},{"cell_type":"code","source":"vocab_size = tokenizer.vocab_size\nembedding_dim = 16\nbatch_size = 512\n\nbi_rnn_model = keras.models.Sequential([\n    keras.layers.Embedding(vocab_size, embedding_dim),\n    keras.layers.Bidirectional(\n        keras.layers.LSTM(\n            units = 32, return_sequences = False)),\n    keras.layers.Dense(32, activation = 'relu'),\n    keras.layers.Dense(1, activation='sigmoid'),\n])\n\nbi_rnn_model.summary()\nbi_rnn_model.compile(optimizer = 'adam',\n                     loss = 'binary_crossentropy',\n                     metrics = ['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-02T09:19:31.901823Z","iopub.execute_input":"2024-02-02T09:19:31.902332Z","iopub.status.idle":"2024-02-02T09:19:32.664212Z","shell.execute_reply.started":"2024-02-02T09:19:31.902296Z","shell.execute_reply":"2024-02-02T09:19:32.662883Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Model: \"sequential_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding_5 (Embedding)     (None, None, 16)          130960    \n                                                                 \n bidirectional_4 (Bidirecti  (None, 64)                12544     \n onal)                                                           \n                                                                 \n dense_8 (Dense)             (None, 32)                2080      \n                                                                 \n dense_9 (Dense)             (None, 1)                 33        \n                                                                 \n=================================================================\nTotal params: 145617 (568.82 KB)\nTrainable params: 145617 (568.82 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = bi_rnn_model.fit(\n    train_dataset,\n    #因为之前30次过拟合，这里改为10次\n    epochs = 10,\n    validation_data = test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T09:19:35.407619Z","iopub.execute_input":"2024-02-02T09:19:35.408531Z","iopub.status.idle":"2024-02-02T09:19:35.531493Z","shell.execute_reply.started":"2024-02-02T09:19:35.408429Z","shell.execute_reply":"2024-02-02T09:19:35.529067Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mbi_rnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#因为之前30次过拟合，这里改为10次\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/tmp/__autograph_generated_filee68lskxw.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_3' (type Sequential).\n    \n    Input 0 of layer \"bidirectional_4\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, None, None, 16)\n    \n    Call arguments received by layer 'sequential_3' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, None, None), dtype=int64)\n      • training=True\n      • mask=None\n"],"ename":"ValueError","evalue":"in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_3' (type Sequential).\n    \n    Input 0 of layer \"bidirectional_4\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, None, None, 16)\n    \n    Call arguments received by layer 'sequential_3' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, None, None), dtype=int64)\n      • training=True\n      • mask=None\n","output_type":"error"}]},{"cell_type":"code","source":"def plot_learning_curves(history,label,epochs,min_value,max_value):\n    data = {}\n    data[label] = history.history[label]\n    data['val_'+label] = history.history['val_+label']\n    pd.DataFrame(data).plot(figsize = (8,5))\n    plt.grid(True)\n    plt.axis([0,epochs,min_value,max_value])\n    plt.show()\n   \nplot_learning_curves(history,'accuracy',10,0,1)\nplot_learning_curves(history,'loss',10,0,1)\n \n    ","metadata":{"execution":{"iopub.status.busy":"2024-02-02T09:18:13.686772Z","iopub.execute_input":"2024-02-02T09:18:13.687356Z","iopub.status.idle":"2024-02-02T09:18:13.758119Z","shell.execute_reply.started":"2024-02-02T09:18:13.687320Z","shell.execute_reply":"2024-02-02T09:18:13.756324Z"},"trusted":true},"execution_count":29,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxis([\u001b[38;5;241m0\u001b[39m,epochs,min_value,max_value])\n\u001b[1;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 10\u001b[0m plot_learning_curves(\u001b[43mhistory\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m plot_learning_curves(history,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"],"ename":"NameError","evalue":"name 'history' is not defined","output_type":"error"}]}]}